{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1640ed50",
   "metadata": {},
   "source": [
    "# Conformal Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021794e",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**Conformal Prediction (CP)** is a framework that wraps around any predictive model and converts its point predictions into **prediction sets** (or **intervals** for regression) that contain the true label or value with a user-chosen probability (e.g. 90% or 95%).\n",
    "\n",
    "The key appeal of conformal prediction is that it provides **finite-sample, distribution-free coverage guarantees** under very weak assumptions—primarily that the data are **exchangeable**.\n",
    "\n",
    "Conformal prediction is **not a predictive model itself**, but a **calibration layer** applied on top of an existing model such as linear regression, random forests, gradient boosting, or neural networks.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Idea and Goal\n",
    "\n",
    "The main goal of conformal prediction is to answer:\n",
    "\n",
    "> *“How uncertain should I be about this prediction, given how wrong my model has been in the past?”*\n",
    "\n",
    "Instead of outputting a single prediction, conformal prediction outputs a **set of plausible labels** such that, in repeated sampling, the true label lies inside the set with probability at least \\(1 - \\varepsilon\\).\n",
    "\n",
    "This guarantee:\n",
    "- Holds in **finite samples**\n",
    "- Does **not** depend on the correctness of the model\n",
    "- Does **not** assume any parametric form of the noise\n",
    "\n",
    "---\n",
    "\n",
    "## Key Assumption: Exchangeability\n",
    "\n",
    "Conformal prediction relies on **exchangeability** of the data:\n",
    "\n",
    "> The joint distribution of the data does not change under permutations of the sample order.\n",
    "\n",
    "Exchangeability is slightly weaker than i.i.d., but it still excludes:\n",
    "- Strong time dependence\n",
    "- Severe non-stationarity\n",
    "- Uncorrected distribution shift\n",
    "\n",
    "Violations of exchangeability are the most common reason conformal methods fail in practice.\n",
    "\n",
    "---\n",
    "\n",
    "## Full (Transductive) Conformal Prediction\n",
    "\n",
    "### High-Level Intuition\n",
    "\n",
    "For a new input \\(x_{n+1}\\), conformal prediction:\n",
    "1. Tries each possible label \\(y\\)\n",
    "2. Measures how “strange” the pair \\((x_{n+1}, y)\\) looks compared to past data\n",
    "3. Keeps only labels that are **not unusually strange**\n",
    "\n",
    "---\n",
    "\n",
    "### Step-by-Step Algorithm\n",
    "\n",
    "#### 1. Choose a nonconformity measure\n",
    "\n",
    "A **nonconformity score** maps a labeled example \\((x_i, y_i)\\) to a real number measuring how unusual it is.\n",
    "\n",
    "Examples:\n",
    "- Regression:  \n",
    "  \\[\n",
    "  \\alpha_i = |y_i - \\hat{f}(x_i)|\n",
    "  \\]\n",
    "- Classification:  \n",
    "  \\[\n",
    "  \\alpha_i = 1 - \\hat{P}(y_i \\mid x_i)\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Augment data with a candidate label\n",
    "\n",
    "For a new input \\(x_{n+1}\\), consider a candidate label \\(y\\).\n",
    "\n",
    "Temporarily add \\((x_{n+1}, y)\\) to the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Refit (if using full conformal) and compute scores\n",
    "\n",
    "Train or refit the underlying model on all \\(n+1\\) points and compute nonconformity scores:\n",
    "\\[\n",
    "\\alpha_1, \\alpha_2, \\dots, \\alpha_{n+1}\n",
    "\\]\n",
    "\n",
    "Let \\(\\alpha_{n+1}\\) be the score of the candidate example.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Compute the conformal p-value\n",
    "\n",
    "\\[\n",
    "p(y) = \\frac{|\\{ i : \\alpha_i \\ge \\alpha_{n+1} \\}|}{n+1}\n",
    "\\]\n",
    "\n",
    "Under exchangeability, these p-values are uniformly (or conservatively) distributed.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Form the prediction set\n",
    "\n",
    "For a target error rate \\(\\varepsilon\\):\n",
    "\\[\n",
    "\\mathcal{C}(x_{n+1}) = \\{ y : p(y) > \\varepsilon \\}\n",
    "\\]\n",
    "\n",
    "This set contains the true label with probability at least \\(1 - \\varepsilon\\).\n",
    "\n",
    "---\n",
    "\n",
    "### Practical Limitation\n",
    "\n",
    "Full conformal prediction requires retraining or reevaluating the model **for each candidate label**, which is computationally expensive for modern models.\n",
    "\n",
    "---\n",
    "\n",
    "## Split Conformal Prediction (Practical Variant)\n",
    "\n",
    "Split conformal prediction avoids repeated retraining and is the most widely used version in practice.\n",
    "\n",
    "---\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. **Split data** into:\n",
    "   - Training set\n",
    "   - Calibration set\n",
    "\n",
    "2. **Train the base model** on the training set only.\n",
    "\n",
    "3. **Compute nonconformity scores** on the calibration set:\n",
    "   - Regression: residuals\n",
    "   - Classification: misclassification or probability-based scores\n",
    "\n",
    "4. **Compute a quantile** of calibration scores:\n",
    "   \\[\n",
    "   q = \\text{Quantile}_{(1-\\varepsilon)\\left(1 + \\frac{1}{n_{\\text{cal}} + 1}\\right)}\n",
    "   \\]\n",
    "\n",
    "5. **Predict for new data**:\n",
    "   - Regression interval:\n",
    "     \\[\n",
    "     [\\hat{y}(x) - q,\\ \\hat{y}(x) + q]\n",
    "     \\]\n",
    "   - Classification set:\n",
    "     include all labels whose scores are below the threshold\n",
    "\n",
    "---\n",
    "\n",
    "### Why Split Conformal Works\n",
    "\n",
    "Even without retraining, the calibration residuals remain exchangeable with future residuals, preserving finite-sample coverage guarantees.\n",
    "\n",
    "---\n",
    "\n",
    "## What the Guarantees Mean\n",
    "\n",
    "The main guarantee is **marginal coverage**:\n",
    "\n",
    "> Over repeated draws of the entire dataset (training, calibration, and test point), the prediction set contains the true label with probability at least \\(1 - \\varepsilon\\).\n",
    "\n",
    "Important clarifications:\n",
    "- Coverage is **not conditional on a specific \\(x\\)**\n",
    "- Some subpopulations may be over- or under-covered\n",
    "- Guarantees are frequentist, not Bayesian\n",
    "\n",
    "---\n",
    "\n",
    "## Online and Streaming Conformal Prediction\n",
    "\n",
    "Conformal prediction can be adapted to streaming settings:\n",
    "- Produces approximately independent error indicators\n",
    "- Enables real-time monitoring of coverage\n",
    "- Useful for detecting concept drift and distribution shift\n",
    "\n",
    "---\n",
    "\n",
    "## Pros\n",
    "\n",
    "### Distribution-free, finite-sample guarantees\n",
    "Valid coverage without assumptions on:\n",
    "- Noise distribution\n",
    "- Linearity\n",
    "- Model correctness\n",
    "\n",
    "Only exchangeability is required.\n",
    "\n",
    "---\n",
    "\n",
    "### Model-agnostic\n",
    "Works with any predictor:\n",
    "- Linear models\n",
    "- Tree-based models\n",
    "- Neural networks\n",
    "- Black-box systems\n",
    "\n",
    "---\n",
    "\n",
    "### Simple and scalable (split conformal)\n",
    "Requires only:\n",
    "- A train–calibration split\n",
    "- Computing empirical quantiles\n",
    "\n",
    "Easy to integrate into existing pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "### Finite-sample validity\n",
    "Guarantees hold at **any sample size**, not just asymptotically.\n",
    "\n",
    "---\n",
    "\n",
    "### Useful for monitoring and diagnostics\n",
    "Nonconformity scores and p-values can flag:\n",
    "- Outliers\n",
    "- Distribution shifts\n",
    "- Concept drift\n",
    "\n",
    "---\n",
    "\n",
    "## Cons\n",
    "\n",
    "### High computational cost (full conformal)\n",
    "Full conformal prediction is often infeasible for:\n",
    "- Large datasets\n",
    "- Deep or complex models\n",
    "\n",
    "---\n",
    "\n",
    "### Marginal, not conditional, coverage\n",
    "Standard conformal methods:\n",
    "- Guarantee coverage on average\n",
    "- Do **not** ensure equal coverage across subgroups or feature regions\n",
    "\n",
    "---\n",
    "\n",
    "### Large prediction sets when the model is weak\n",
    "If the base model performs poorly:\n",
    "- Prediction intervals become wide\n",
    "- Classification sets include many labels\n",
    "\n",
    "This is statistically valid but may be operationally unhelpful.\n",
    "\n",
    "---\n",
    "\n",
    "### Exchangeability violations in real data\n",
    "Time series, non-stationarity, and regime changes can break assumptions unless:\n",
    "- Adaptive conformal\n",
    "- Online conformal\n",
    "- Covariate-conditional variants are used\n",
    "\n",
    "---\n",
    "\n",
    "### Design choices affect efficiency\n",
    "Choices of:\n",
    "- Nonconformity score\n",
    "- Data splitting strategy\n",
    "- Calibration window size\n",
    "\n",
    "directly impact the tightness and usefulness of prediction sets.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Conformal prediction provides **honest uncertainty** by calibrating predictions against historical errors rather than modeling uncertainty explicitly.\n",
    "\n",
    "It excels when:\n",
    "- Coverage guarantees matter\n",
    "- Models are black-box\n",
    "- Distributional assumptions are risky\n",
    "\n",
    "But it requires care under:\n",
    "- Distribution shift\n",
    "- Heterogeneous subpopulations\n",
    "- Real-time, non-stationary systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf8b07",
   "metadata": {},
   "source": [
    "# Split Conformal Prediction\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Split Conformal Prediction** is a practical and scalable variant of conformal prediction.  \n",
    "It transforms point predictions from any base model into **prediction sets or intervals** with **finite-sample coverage guarantees**.\n",
    "\n",
    "Given a user-chosen miscoverage level \\(\\alpha\\) (e.g. \\(\\alpha = 0.1\\) for 90% coverage), split conformal prediction guarantees at least \\(1 - \\alpha\\) marginal coverage **in finite samples**, under the assumption of **exchangeability**, conditional on the training set.\n",
    "\n",
    "---\n",
    "\n",
    "## Intuition\n",
    "\n",
    "> *Use a held-out calibration set to measure how wrong the model tends to be, and then inflate future predictions just enough to guarantee coverage.*\n",
    "\n",
    "Split conformal avoids repeated retraining by separating **model fitting** and **uncertainty calibration**.\n",
    "\n",
    "---\n",
    "\n",
    "## General Algorithm\n",
    "\n",
    "Split conformal prediction applies to **any base model** and works for both **regression** and **classification**.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Split the data\n",
    "\n",
    "Divide the dataset into two disjoint parts:\n",
    "\n",
    "- **Proper training set** \\(D_1\\), size \\(n_1\\)\n",
    "- **Calibration set** \\(D_2\\), size \\(n_2\\)\n",
    "\n",
    "A common choice is a 50/50 split, though larger calibration sets improve the stability of the coverage.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Train the base model\n",
    "\n",
    "Train the predictor \\(\\hat{f}_{n_1}\\) using only the training set \\(D_1\\):\n",
    "\n",
    "\\[\n",
    "\\hat{f}_{n_1} \\leftarrow \\text{Train}(D_1)\n",
    "\\]\n",
    "\n",
    "The calibration data must not be used for training.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Compute calibration nonconformity scores\n",
    "\n",
    "For each calibration example \\((X_i, Y_i) \\in D_2\\), compute a **nonconformity score**:\n",
    "\n",
    "\\[\n",
    "R_i = V(X_i, Y_i)\n",
    "\\]\n",
    "\n",
    "where \\(V(\\cdot)\\) is **negatively oriented** (smaller values indicate better conformity).\n",
    "\n",
    "**Common choices:**\n",
    "- Regression:  \n",
    "  \\[\n",
    "  V(x, y) = |y - \\hat{f}_{n_1}(x)|\n",
    "  \\]\n",
    "- Classification:  \n",
    "  \\[\n",
    "  V(x, y) = 1 - \\hat{P}(y \\mid x)\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Compute the conformal quantile\n",
    "\n",
    "Let \\(\\{R_1, \\dots, R_{n_2}\\}\\) be the calibration scores.\n",
    "\n",
    "Define the conformal threshold:\n",
    "\n",
    "\\[\n",
    "\\hat{q}_{n_2} =\n",
    "\\text{the } \\left\\lceil (1 - \\alpha)(n_2 + 1) \\right\\rceil\n",
    "\\text{-th smallest value of } \\{R_i\\}\n",
    "\\]\n",
    "\n",
    "This quantile choice ensures finite-sample coverage.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Predict for a new input\n",
    "\n",
    "For a new input \\(x\\), define the conformal prediction set:\n",
    "\n",
    "\\[\n",
    "\\hat{C}_n(x) = \\{ y : V(x, y) \\le \\hat{q}_{n_2} \\}\n",
    "\\]\n",
    "\n",
    "This set contains the true label with probability at least \\(1 - \\alpha\\).\n",
    "\n",
    "---\n",
    "\n",
    "## Regression Case\n",
    "\n",
    "For regression, using absolute residuals as the nonconformity score:\n",
    "\n",
    "\\[\n",
    "V(x, y) = |y - \\hat{f}(x)|\n",
    "\\]\n",
    "\n",
    "the conformal prediction set becomes an **interval**:\n",
    "\n",
    "\\[\n",
    "\\boxed{\n",
    "\\left[\n",
    "\\hat{f}(x) - \\hat{q}_{n_2},\n",
    "\\;\n",
    "\\hat{f}(x) + \\hat{q}_{n_2}\n",
    "\\right]\n",
    "}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## Coverage Guarantee\n",
    "\n",
    "Under exchangeability, split conformal prediction satisfies:\n",
    "\n",
    "\\[\n",
    "\\mathbb{P}\\left( Y_{\\text{new}} \\in \\hat{C}_n(X_{\\text{new}}) \\right) \\ge 1 - \\alpha\n",
    "\\]\n",
    "\n",
    "Key points:\n",
    "- The guarantee is **finite-sample**, not asymptotic\n",
    "- Coverage is **marginal**, not conditional on a specific \\(x\\)\n",
    "- Valid **conditional on the trained model**\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Notes\n",
    "\n",
    "- Larger calibration sets → more stable quantiles\n",
    "- Weak base models → wider prediction intervals\n",
    "- Exchangeability violations (e.g. time series, drift) require adaptive or online variants\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Split conformal prediction is a simple, model-agnostic method to obtain **honest uncertainty estimates**:\n",
    "\n",
    "- Train once\n",
    "- Calibrate once\n",
    "- Predict with guaranteed coverage\n",
    "\n",
    "It is widely used because it scales to complex models while preserving strong statistical guarantees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269bcb28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor  \u001b[38;5;66;03m# Or any model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Assume X_train (n x d), y_train (n,)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X_cal, X_prop, y_cal, y_prop \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX_train\u001b[49m, y_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train on proper training set\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor()  \u001b[38;5;66;03m# Replace with your model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor  # Or any model\n",
    "\n",
    "# Assume X_train (n x d), y_train (n,)\n",
    "X_cal, X_prop, y_cal, y_prop = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train on proper training set\n",
    "model = RandomForestRegressor()  # Replace with your model\n",
    "model.fit(X_prop, y_prop)\n",
    "\n",
    "# Calibration residuals (absolute)\n",
    "residuals = np.abs(y_cal - model.predict(X_cal))\n",
    "\n",
    "# Adjusted quantile for alpha=0.1 (90% coverage)\n",
    "alpha = 0.1\n",
    "q_hat = np.quantile(residuals, ((n_cal + 1) * (1 - alpha)) / n_cal)  # Equivalent form\n",
    "\n",
    "# Predict interval for new x_test\n",
    "point_pred = model.predict(x_test)\n",
    "lower = point_pred - q_hat\n",
    "upper = point_pred + q_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d90d7",
   "metadata": {},
   "source": [
    "This yields intervals with coverage in \n",
    "[\n",
    "1\n",
    "−\n",
    "α\n",
    ",\n",
    "1\n",
    "−\n",
    "α\n",
    "+\n",
    "1\n",
    "/\n",
    "(\n",
    "n\n",
    "2\n",
    "+\n",
    "1\n",
    ")\n",
    "]\n",
    "[1−α,1−α+1/(n \n",
    "2\n",
    " +1)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa6729",
   "metadata": {},
   "source": [
    "## Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068fdec",
   "metadata": {},
   "source": [
    "For multiclass, use \n",
    "V\n",
    "(\n",
    "x\n",
    ",\n",
    "y\n",
    ")\n",
    "=\n",
    "−\n",
    "p\n",
    "^\n",
    "y\n",
    "(\n",
    "x\n",
    ")\n",
    "V(x,y)=− \n",
    "p\n",
    "^\n",
    "  \n",
    "y\n",
    " (x) (negative log-prob or 1 - prob of class y). Include classes where score ≤ \n",
    "q\n",
    "^\n",
    "n\n",
    "2\n",
    "q\n",
    "^\n",
    "  \n",
    "n \n",
    "2\n",
    " \n",
    " .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# After split and model.fit(X_prop, y_prop) as above (classifier)\n",
    "\n",
    "# Calibration scores: negative prob of true class\n",
    "probs_cal = model.predict_proba(X_cal)\n",
    "true_probs_cal = np.array([row[y] for row, y in zip(probs_cal, y_cal)])  # Prob of true label\n",
    "residuals = -true_probs_cal  # Or np.log(1 - true_probs_cal + 1e-10)\n",
    "\n",
    "q_hat = np.quantile(residuals, ((n_cal + 1) * (1 - alpha)) / n_cal)\n",
    "\n",
    "# For new x_test\n",
    "probs_test = model.predict_proba(x_test.reshape(1, -1))[0]\n",
    "pred_set = np.where(-probs_test <= q_hat)[0]  # Classes in set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c97446c",
   "metadata": {},
   "source": [
    "Libraries and Tips\n",
    "MAPIE (Python): from mapie.regression import MapieRegressor; mapie = MapieRegressor(model, method='plus'); mapie.fit(X_prop, y_prop); y_pred, y_pis = mapie.predict(X_test, alpha=0.1) for split conformal.\n",
    "\n",
    "ConformalPrediction.jl (Julia) or tidymodels (R) for other languages.\n",
    "\n",
    "Use studentized residuals \n",
    "V\n",
    "(\n",
    "x\n",
    ",\n",
    "y\n",
    ")\n",
    "=\n",
    "∣\n",
    "y\n",
    "−\n",
    "f\n",
    "^\n",
    "(\n",
    "x\n",
    ")\n",
    "∣\n",
    "/\n",
    "σ\n",
    "^\n",
    "(\n",
    "x\n",
    ")\n",
    "V(x,y)=∣y− \n",
    "f\n",
    "^\n",
    " (x)∣/ \n",
    "σ\n",
    "^\n",
    " (x) for heteroscedastic data (train extra spread model \n",
    "σ\n",
    "^\n",
    "σ\n",
    "^\n",
    " ).\n",
    "​\n",
    "\n",
    "Larger calibration set (\n",
    "n\n",
    "2\n",
    "≥\n",
    "100\n",
    "n \n",
    "2\n",
    " ≥100) reduces coverage variance.\n",
    "\n",
    "For efficiency, better base models yield tighter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4602a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c4fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44746fea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airline_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
